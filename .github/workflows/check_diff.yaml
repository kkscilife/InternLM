name: demo-in-readme
on: 
  push:
  pull_request:
    branches:
      - "main"
      - "develop"
    paths-ignore:
      - "docs/**"
      - "**.md"
env:
  WORKSPACE_PREFIX: $(echo $GITHUB_WORKSPACE |cut -d '/' -f 1-4)
  SLURM_PARTITION: llm_s

jobs:
  check-requirements:
    runs-on: [t_cluster]
    steps:
    - name: mask env
      run: |
        echo "::add-mask::${{env.WORKSPACE_PREFIX}}"
    - uses: actions/checkout@v3
      with:
         fetch-depth: 2
    - name: check-requirements
      run: |
        source activate internlm-env-test
        changed_files=$(git diff --name-only -r HEAD^1 HEAD)
        echo $changed_files
        if [[ $changed_files =~ "runtime.txt" ]]; then
          pip install -r requirements/runtime.txt
        fi

        if [[ $changed_files =~ "torch.txt"  ]]; then
          pip install -r requirements/torch.txt
        fi

  dataset-preparation:
    if: ${{ !cancelled() }}
    needs: check-requirements
    runs-on: [t_cluster]
    steps:
    - name: mask env
      run: |
        echo "::add-mask::${{env.WORKSPACE_PREFIX}}"
    - uses: actions/checkout@v3

    - name: raw-chinese-data
      run: |
        source activate internlm-env-test
        sleep 180
        #sh ./ci_scripts/data/tokenizer_chinese.sh ${GITHUB_RUN_ID}-${GITHUB_JOB}

    - name: alpaca-data
      run: |
        source activate internlm-env-test
       # sh ./ci_scripts/data/tokenizer_alpaca.sh

  train:
    if: ${{ !cancelled() }}
    needs: check-requirements
    runs-on: [t_cluster]
    timeout-minutes: 30
    steps:
    - name: mask env
      run: |
        echo "::add-mask::${{env.WORKSPACE_PREFIX}}"
    - uses: actions/checkout@v3

    - name: slurm-train
      id: basic_train
      run: |
        source activate internlm-env-test
        sleep 300
        #sh ./ci_scripts/train/slurm_train.sh ${GITHUB_RUN_ID}-${GITHUB_JOB}

    - name: load_preset_ckpt
      if: ${{ failure() && steps.basic_train.conclusion == 'failure' }}
      run: |
        source activate internlm-env-test
        export PYTHONPATH=$PWD:$PYTHONPATH
        #sh ./ci_scripts/train/load_ckpt.sh 7B_load_preset_ckpt ${GITHUB_RUN_ID}-${GITHUB_JOB}

    - name: load_new_ckpt
      run: |
        sleep 500
        

    - name: torchrun-train
      run: |
        source activate internlm-env-test
        sleep 3

  convert-model-then-load:
    if: ${{ !cancelled() }}
    needs: check-requirements
    runs-on: [t_cluster]
    timeout-minutes: 15
    steps:
    - name: mask env
      run: |
        echo "::add-mask::${{env.WORKSPACE_PREFIX}}"
    - uses: actions/checkout@v3

    - name: convert-model-then-load
      run: |
        source activate internlm-env-test
        export PYTHONPATH=$PWD:$PYTHONPATH
        sleep 120
  load-chat-model-in-hf:
    if: ${{ !cancelled() }}
    needs: check-requirements
    runs-on: [t_cluster]
    timeout-minutes: 15
    steps:
    - name: mask env
      run: |
        echo "::add-mask::${{env.WORKSPACE_PREFIX}}"
    - uses: actions/checkout@v3

    - name: chat-model-in-hf
      run: |
        source activate internlm-env-test
        sleep 300
