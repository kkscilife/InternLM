name: demo-in-readme
on: 
  push:
    branches:
      - "debug/test"
      - "new/tmp"
  pull_request:
    branches:
      - "main"
      - "develop"
    paths-ignore:
      - "docs/**"
      - "**.md"
     
#env:
  #NEW_PREFIX: ${{env.NEW_PREFIX}}

jobs:
  dataset-preparation:
    runs-on: [lmtest]
    steps:
        
    - uses: actions/checkout@v3
      with:
         fetch-depth: 2

    - name: raw-chinese-data
      run: |
        source activate internlm-env-test
        echo "show env info"
        echo $GITHUB_WORKSPACE
        dir_prefix=$(echo $GITHUB_WORKSPACE |cut -d '/' -f 1-4)/data
        #echo $prefix
        echo "NEW_PREFIX=$(echo $(dir_prefix))" >> "$GITHUB_ENV" 
        echo "${{env.NEW_PREFIX}}"
        #echo ${{ github.head_ref }}
        #echo 'debuging'
        #echo ${{ github.base_ref }}
        files=$(git diff --name-only -r HEAD^1 HEAD)
        echo $files
        if [[ $files =~ "runtime.txt" ]]; then
          echo 'pip install -r requirements/runtime.txt'
        fi
        
        if [[ $files =~ "torch.txt"  ]]; then
          echo 'pip install -r requirements/torch.txt'
        fi
        echo "WK_PREFIX=$(echo $GITHUB_WORKSPACE |cut -d '/' -f 1-4)" >> "$GITHUB_ENV"
        echo "${{env.WK_PREFIX}}"
        #sh ./ci_scripts/data/tokenizer_chinese.sh


  
  load-chat-model-in-hf:
    if: ${{ always() }}
    needs: dataset-preparation
    runs-on: [lmtest]
    steps:
    - uses: actions/checkout@v3

    - name: chat-model-in-hf
      run: |
        #echo ${{ secrets.NEW_PREFIX }}
        echo "${{ env.NEW_PREFIX}}"
        source activate internlm-env-test
        sh ci_scripts/data/tmp.sh
        
        
        #srun -p llm2 python ./ci_scripts/model/demo_load_7B_chat_model.py
